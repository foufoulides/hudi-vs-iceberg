{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Athena Iceberg - Data Eng Use Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import awswrangler as wr\n",
    "import pydbtools as pydb\n",
    "import py_aws_vault_auth\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison = \"athena_iceberg\"\n",
    "region = \"eu-west-1\"\n",
    "bucketname = \"sb-test-bucket-ireland\"\n",
    "db_name = \"wto_hudi_iceberg\"\n",
    "s3_root_folder = \"wo/de_use_cases\"\n",
    "s3_base_path = f\"s3://{bucketname}/{s3_root_folder}/{comparison}\"\n",
    "db_base_path = f\"{s3_base_path}database/\"\n",
    "\n",
    "environ_auth = py_aws_vault_auth.authenticate(\"sso-sandbox\", prompt=\"python\", return_as=\"environ\")\n",
    "os.environ.update(environ_auth)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bulk insert and add curation columns "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up variables for bulk insert test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "senario = \"bulk_insert\"\n",
    "source_fl = f\"s3://sb-test-bucket-ireland/dummy_data/full_load/\"\n",
    "source_ud = f\"s3://sb-test-bucket-ireland/dummy_data/updates/\"\n",
    "temp_table_name = f\"{comparison}_{senario}_temp\"\n",
    "dest_table_name = f\"{comparison}_{senario}_iceberg\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a temporary table from source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_table_sql_1 = f\"\"\"\n",
    "    CREATE EXTERNAL TABLE IF NOT EXISTS {db_name}.{temp_table_name} (\n",
    "        product_id string,\n",
    "        product_name string,\n",
    "        price int,\n",
    "        extraction_timestamp timestamp,\n",
    "        op string\n",
    "    )\n",
    "    STORED AS PARQUET\n",
    "    LOCATION '{source_fl}'\n",
    "\"\"\"\n",
    "#wr.athena.read_sql_query(sql=temp_table_sql, database=db_name, ctas_approach=False)\n",
    "# wr.athena.read_sql_query(f\"DROP TABLE {temp_table_name}\", database=db_name, ctas_approach=False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that the table is populated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wr.athena.read_sql_query(f\"SELECT * FROM {temp_table_name}\", database=db_name, ctas_approach=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an iceberg table from source table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dest_table_sql = f\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS {db_name}.{dest_table_name}\n",
    "        WITH (table_type='ICEBERG',\n",
    "        location='{db_base_path}{senario}/',\n",
    "        format='PARQUET',\n",
    "        is_external=false)\n",
    "        AS SELECT\n",
    "            product_id,\n",
    "            product_name,\n",
    "            price,\n",
    "            CAST(extraction_timestamp AS timestamp(6)) AS extraction_timestamp,\n",
    "            op \n",
    "           FROM {db_name}.{temp_table_name};\n",
    "\"\"\"\n",
    "wr.athena.read_sql_query(sql=dest_table_sql, database=db_name, ctas_approach=False, workgroup='Athena3')\n",
    "wr.athena.read_sql_query(f\"SELECT * FROM {dest_table_name}\", database=db_name, ctas_approach=False, workgroup='Athena3')\n",
    "##wr.athena.delete_table(database=db_name, table=temp_table_name)\n",
    "\n",
    "## 13 sec"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update destination iceberg table with new columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_columns_sql = f\"\"\"\n",
    "    ALTER TABLE {db_name}.{dest_table_name}\n",
    "    ADD COLUMNS (start_datetime TIMESTAMP, end_datetime TIMESTAMP, is_current BOOLEAN)\n",
    "\"\"\"\n",
    "update_values_sql = f\"\"\"\n",
    "    UPDATE {db_name}.{dest_table_name}\n",
    "    SET start_datetime = extraction_timestamp, \n",
    "        end_datetime = CAST(TIMESTAMP '2250-01-01' as TIMESTAMP(6)), \n",
    "        is_current = true\n",
    "\"\"\"\n",
    "#wr.athena.read_sql_query(sql=update_values_sql, database=db_name, ctas_approach=False, workgroup='Athena3')\n",
    "print(\"Updated values\")\n",
    "wr.athena.read_sql_query(f\"SELECT * FROM {dest_table_name}\", database=db_name, ctas_approach=False, workgroup='Athena3')\n",
    "##wr.athena.delete_table(database=db_name, table=temp_table_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete and recreate tempory table from update file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wr.athena.read_sql_query(f\"DROP TABLE IF EXISTS {temp_table_name}\", database=db_name, ctas_approach=False)\n",
    "temp_table_sql = f\"\"\"\n",
    "    CREATE EXTERNAL TABLE {db_name}.{temp_table_name} (\n",
    "        product_id string,\n",
    "        product_name string,\n",
    "        price int,\n",
    "        extraction_timestamp timestamp,\n",
    "        op string\n",
    "    )\n",
    "    STORED AS PARQUET\n",
    "    LOCATION '{source_ud}'\n",
    "\"\"\"\n",
    "wr.athena.read_sql_query(sql=temp_table_sql, database=db_name, ctas_approach=False)\n",
    "wr.athena.read_sql_query(f\"SELECT * FROM {temp_table_name}\", database=db_name, ctas_approach=False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update destination table when key is source (CDC / update) table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_dest_sql = f\"\"\"\n",
    "    MERGE INTO {db_name}.{dest_table_name} dest\n",
    "        USING {db_name}.{temp_table_name} sour\n",
    "            ON sour.product_id = dest.product_id\n",
    "    WHEN MATCHED AND dest.is_current = TRUE AND sour.extraction_timestamp > dest.extraction_timestamp\n",
    "        THEN UPDATE\n",
    "            SET end_datetime = sour.extraction_timestamp, is_current = FALSE;\n",
    "\"\"\"\n",
    "wr.athena.read_sql_query(sql=update_dest_sql, database=db_name, ctas_approach=False)\n",
    "wr.athena.read_sql_query(f\"SELECT * FROM {dest_table_name}\", database=db_name, ctas_approach=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insert all updates from source table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insert_dest_sql = f\"\"\"\n",
    "INSERT INTO {db_name}.{dest_table_name}\n",
    "    SELECT product_id, product_name, price, CAST(extraction_timestamp AS TIMESTAMP(6)), op, \n",
    "      CAST(extraction_timestamp AS TIMESTAMP(6)), CAST(TIMESTAMP '2250-01-01' as TIMESTAMP(6)),TRUE\n",
    "    FROM {db_name}.{temp_table_name}\n",
    "\"\"\"\n",
    "wr.athena.read_sql_query(sql=update_dest_sql, database=db_name, ctas_approach=False)\n",
    "wr.athena.read_sql_query(f\"SELECT * FROM {dest_table_name}\", database=db_name, ctas_approach=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wr.athena.read_sql_query(sql=temp_table_sql, database=db_name, ctas_approach=False)\n",
    "wr.athena.read_sql_query(f\"DROP TABLE {temp_table_name}\", database=db_name, ctas_approach=False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of changes\n",
    "\n",
    "**SETUP**\n",
    "1. Create a temp table from FL\n",
    "2. Create iceberg full load via CTAS, adding mojap fields\n",
    "3. Create CDC temp table \n",
    "4. Create a CDC view adding mojap fields (didnt actualy do this last light as plain insert was quick enough for Sou's critera)\n",
    "\n",
    "**PROCESSING**\n",
    "1. Use merge to close is_current records in iceberg that exist in CDC (there is an issue of closing date flif multiple CDC)\n",
    "2. Insert CDC into iceberg\n",
    "\n",
    "**NEXT STEPS**\n",
    "1. Run processing as a single step\n",
    "2. Update the cdc insrt to a view\n",
    "3. Close multiple CDC updates with previous date\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
