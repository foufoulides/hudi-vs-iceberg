{
	"cells": [
		{
			"cell_type": "markdown",
			"metadata": {
				"editable": true,
				"trusted": true
			},
			"source": []
		},
		{
			"cell_type": "markdown",
			"metadata": {
				"editable": true
			},
			"source": [
				"## Glue + Iceberg evaluation"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"###### Bulk Insert \n",
				"###### SCD2\n",
				"###### Impute deletions\n",
				"###### Deduplication\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [],
			"source": []
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"## Initialise SparkSession"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"## Bulk Insert \n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [],
			"source": [
				"## Initialise SparkSession"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 5,
			"metadata": {
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"Welcome to the Glue Interactive Sessions Kernel\n",
						"For more information on available magic commands, please type %help in any new cell.\n",
						"\n",
						"Please view our Getting Started page to access the most up-to-date information on the Interactive Sessions kernel: https://docs.aws.amazon.com/glue/latest/dg/interactive-sessions.html\n",
						"Installed kernel version: 0.37.3 \n",
						"Setting session ID prefix to native-iceberg-dataframe-\n",
						"Setting Glue version to: 3.0\n",
						"Current idle_timeout is 2800 minutes.\n",
						"idle_timeout has been set to 60 minutes.\n",
						"The following configurations have been updated: {'--conf': 'spark.sql.extensions=org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions', '--datalake-formats': 'iceberg'}\n"
					]
				}
			],
			"source": [
				"%session_id_prefix native-iceberg-dataframe-\n",
				"%glue_version 3.0\n",
				"%idle_timeout 60\n",
				"%%configure \n",
				"{\n",
				"  \"--conf\": \"spark.sql.extensions=org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions\",\n",
				"  \"--datalake-formats\": \"iceberg\"\n",
				"}"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 12,
			"metadata": {
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"\n"
					]
				}
			],
			"source": [
				"catalog_name = \"glue_catalog\"\n",
				"bucket_name = \"sb-test-bucket-ireland\"\n",
				"bucket_prefix = \"sb\"\n",
				"database_name = \"n2_iceberg_dataframe\"\n",
				"table_name = \"datagensb\"\n",
				"warehouse_path = f\"s3://{bucket_name}/{bucket_prefix}\""
			]
		},
		{
			"cell_type": "code",
			"execution_count": 13,
			"metadata": {
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"\n"
					]
				}
			],
			"source": [
				"from pyspark.sql import SparkSession\n",
				"spark = SparkSession.builder \\\n",
				"    .config(f\"spark.sql.catalog.{catalog_name}\", \"org.apache.iceberg.spark.SparkCatalog\") \\\n",
				"    .config(f\"spark.sql.catalog.{catalog_name}.warehouse\", f\"{warehouse_path}\") \\\n",
				"    .config(f\"spark.sql.catalog.{catalog_name}.catalog-impl\", \"org.apache.iceberg.aws.glue.GlueCatalog\") \\\n",
				"    .config(f\"spark.sql.catalog.{catalog_name}.io-impl\", \"org.apache.iceberg.aws.s3.S3FileIO\") \\\n",
				"    .config(\"spark.sql.extensions\",\"org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions\") \\\n",
				"    .getOrCreate()"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 14,
			"metadata": {
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"DataFrame[]\n"
					]
				}
			],
			"source": [
				"query = f\"\"\"\n",
				"CREATE DATABASE IF NOT EXISTS {catalog_name}.{database_name}\n",
				"\"\"\"\n",
				"spark.sql(query)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [],
			"source": []
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [],
			"source": []
		},
		{
			"cell_type": "code",
			"execution_count": 4,
			"metadata": {
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"\n"
					]
				}
			],
			"source": [
				"full_load = spark.read.option('header','true').parquet(\"s3://sb-test-bucket-ireland/data-engineering-use-cases/dummy-data/full_load.parquet\")"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 6,
			"metadata": {
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [],
			"source": [
				"#"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 5,
			"metadata": {
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"\n"
					]
				}
			],
			"source": [
				"import pyspark.sql.functions as f"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 6,
			"metadata": {
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"\n"
					]
				}
			],
			"source": [
				"\n",
				"full_load = full_load.withColumn(\"start_datetime\",f.col(\"extraction_timestamp\"))\n",
				"full_load = full_load.withColumn(\"end_datetime\", f.to_timestamp(f.lit(future_end_datetime), 'yyyy-MM-dd'))\n",
				"full_load = full_load.withColumn(\"op\",f.lit(\"None\"))\n",
				"full_load = full_load.withColumn(\"is_current\",f.lit(True))\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [],
			"source": [
				"# delete later\n",
				"full_load = full_load.withColumn(\"start_datetime\",f.col(\"extraction_timestamp\"))\n",
				"full_load = full_load.withColumn(\"end_datetime\", f.to_timestamp(f.lit(\"2050-01-01\"), 'yyyy-MM-dd'))\n",
				"full_load = full_load.withColumn(\"op\",f.lit(\"None\"))\n",
				"full_load = full_load.withColumn(\"is_current\",f.lit(True))"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 15,
			"metadata": {
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"\n"
					]
				}
			],
			"source": [
				"input_filepath = \"s3://sb-test-bucket-ireland/data-engineering-use-cases/dummy-data/full_load.parquet\"\n",
				"output_directory = f\"{catalog_name}.{database_name}.{table_name}\"\n",
				"future_end_datetime = \"2050-01-01\""
			]
		},
		{
			"cell_type": "code",
			"execution_count": 6,
			"metadata": {
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"\n"
					]
				}
			],
			"source": [
				"full_load=spark.read.option('header','true').parquet(input_filepath)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 16,
			"metadata": {
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"\n"
					]
				}
			],
			"source": [
				"from pyspark.sql import SparkSession, functions as F\n",
				"from pyspark.sql.types import StructType, StructField, IntegerType, Row\n",
				"import time\n",
				"\n",
				"\n",
				"def bulk_insert(input_filepath,output_directory,future_end_datetime):\n",
				"    start = time.time()\n",
				"    full_load=spark.read.option('header','true').parquet(input_filepath)\n",
				"    full_load = full_load.withColumn(\"start_datetime\",F.col(\"extraction_timestamp\"))\n",
				"    full_load = full_load.withColumn(\"end_datetime\", F.to_timestamp(F.lit(future_end_datetime), 'yyyy-MM-dd'))\n",
				"    full_load = full_load.withColumn(\"op\",F.lit(\"None\"))\n",
				"    full_load = full_load.withColumn(\"is_current\",F.lit(True))\n",
				"    full_load.sortWithinPartitions(\"product_name\") \\\n",
				"    .writeTo(output_directory) \\\n",
				"    .create()\n",
				"    print(time.time()-start)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 17,
			"metadata": {
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"10.97949767112732\n"
					]
				}
			],
			"source": [
				"bulk_insert(input_filepath,output_directory,future_end_datetime)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 7,
			"metadata": {
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [],
			"source": [
				"#full_load = full_load.withColumn(\"'end_datetime'\",f.col(\"extraction_timestamp\"))"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 8,
			"metadata": {
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [],
			"source": [
				"#from pyspark.sql.types import StringType,BooleanType,DateType"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 9,
			"metadata": {
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [],
			"source": [
				"#full_load=full_load.withColumn(\"op\",full_load.op.cast(StringType))"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 7,
			"metadata": {
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"+----------+------------+-----+--------------------+----+\n",
						"|product_id|product_name|price|extraction_timestamp|  op|\n",
						"+----------+------------+-----+--------------------+----+\n",
						"|     00001|      Heater|  250| 2022-01-01 01:01:01|null|\n",
						"|     00002|  Thermostat|  400| 2022-01-01 01:01:01|null|\n",
						"|     00003|  Television|  600| 2022-01-01 01:01:01|null|\n",
						"|     00004|     Blender|  100| 2022-01-01 01:01:01|null|\n",
						"|     00005| USB charger|   50| 2022-01-01 01:01:01|null|\n",
						"+----------+------------+-----+--------------------+----+\n"
					]
				}
			],
			"source": [
				"full_load.show()"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 8,
			"metadata": {
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"\n"
					]
				}
			],
			"source": [
				"full_load.sortWithinPartitions(\"product_name\") \\\n",
				"    .writeTo(f\"{catalog_name}.{database_name}.{table_name}\") \\\n",
				"    .create()"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 9,
			"metadata": {
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"[Table(name='datagensb', database='n1_iceberg_dataframe', description=None, tableType=None, isTemporary=False)]\n"
					]
				}
			],
			"source": [
				"spark.catalog.listTables(database_name)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 10,
			"metadata": {
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"+----------+------------+-----+--------------------+----+-------------------+-------------------+----------+\n",
						"|product_id|product_name|price|extraction_timestamp|  op|     start_datetime|       end_datetime|is_current|\n",
						"+----------+------------+-----+--------------------+----+-------------------+-------------------+----------+\n",
						"|     00004|     Blender|  100| 2022-01-01 01:01:01|None|2022-01-01 01:01:01|2050-01-01 00:00:00|      true|\n",
						"|     00001|      Heater|  250| 2022-01-01 01:01:01|None|2022-01-01 01:01:01|2050-01-01 00:00:00|      true|\n",
						"|     00003|  Television|  600| 2022-01-01 01:01:01|None|2022-01-01 01:01:01|2050-01-01 00:00:00|      true|\n",
						"|     00002|  Thermostat|  400| 2022-01-01 01:01:01|None|2022-01-01 01:01:01|2050-01-01 00:00:00|      true|\n",
						"|     00005| USB charger|   50| 2022-01-01 01:01:01|None|2022-01-01 01:01:01|2050-01-01 00:00:00|      true|\n",
						"+----------+------------+-----+--------------------+----+-------------------+-------------------+----------+\n"
					]
				}
			],
			"source": [
				"spark.table(f\"{catalog_name}.{database_name}.{table_name}\") \\\n",
				"    .show()"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 11,
			"metadata": {
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"+--------------------+-----------------+---------+-------------------+\n",
						"|     made_current_at|      snapshot_id|parent_id|is_current_ancestor|\n",
						"+--------------------+-----------------+---------+-------------------+\n",
						"|2023-05-25 10:40:...|78222291571215463|     null|               true|\n",
						"+--------------------+-----------------+---------+-------------------+\n"
					]
				}
			],
			"source": [
				"spark.table(f\"{catalog_name}.{database_name}.{table_name}.history\") \\\n",
				"    .show()"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [],
			"source": []
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [],
			"source": []
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"## Slowly Changing Dimension Type 2 (SCD2)\n",
				"The updates are created by replacing one column with the same value to simplify the testing. The soft deletes are not taken into account since very similar process from a performance perspective.\n",
				"\n",
				"Steps:\n",
				"\n",
				"Read updates\n",
				"Join full load with updates on primary key\n",
				"Set end_datetime to the extraction_timestamp of the updated records\n",
				"Close the existing records\n",
				"Add curation columms to updates\n",
				"Append updated data to existing data"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 13,
			"metadata": {
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"\n"
					]
				}
			],
			"source": [
				"full_load_updates = spark.read.option('header','true').parquet(\"s3://sb-test-bucket-ireland/data-engineering-use-cases/dummy-data/updates.parquet\")"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [],
			"source": []
		},
		{
			"cell_type": "code",
			"execution_count": 15,
			"metadata": {
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"\n"
					]
				}
			],
			"source": [
				"full_load_updates = full_load_updates.withColumn(\"start_datetime\",f.col(\"extraction_timestamp\"))"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 16,
			"metadata": {
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"\n"
					]
				}
			],
			"source": [
				"full_load_updates = full_load_updates.withColumn(\"end_datetime\", f.to_timestamp(f.lit(\"2050-01-01\"), 'yyyy-MM-dd'))"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 17,
			"metadata": {
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"\n"
					]
				}
			],
			"source": [
				"full_load_updates = full_load_updates.withColumn(\"is_current\",f.lit(True))"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 18,
			"metadata": {
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"+----------+------------+-----+--------------------+---+-------------------+-------------------+----------+\n",
						"|product_id|product_name|price|extraction_timestamp| op|     start_datetime|       end_datetime|is_current|\n",
						"+----------+------------+-----+--------------------+---+-------------------+-------------------+----------+\n",
						"|     00001|      Heater| 1000| 2023-01-01 01:01:01|  U|2023-01-01 01:01:01|2050-01-01 00:00:00|      true|\n",
						"|     00002|  Thermostat| 1000| 2023-01-01 01:01:01|  U|2023-01-01 01:01:01|2050-01-01 00:00:00|      true|\n",
						"|     00003|  Television| 1000| 2023-01-01 01:01:01|  U|2023-01-01 01:01:01|2050-01-01 00:00:00|      true|\n",
						"|     00004|     Blender| 1000| 2023-01-01 01:01:01|  U|2023-01-01 01:01:01|2050-01-01 00:00:00|      true|\n",
						"|     00005| USB charger| 1000| 2023-01-01 01:01:01|  U|2023-01-01 01:01:01|2050-01-01 00:00:00|      true|\n",
						"+----------+------------+-----+--------------------+---+-------------------+-------------------+----------+\n"
					]
				}
			],
			"source": [
				"full_load_updates.show()"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 42,
			"metadata": {
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [],
			"source": [
				"#from pyspark.sql.types import IntegerType"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 43,
			"metadata": {
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [],
			"source": [
				"#full_load_updates = full_load_updates.withColumn(\"op\",full_load_updates[\"op\"].cast(IntegerType()))"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 19,
			"metadata": {
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"StructType(List(StructField(product_id,StringType,true),StructField(product_name,StringType,true),StructField(price,LongType,true),StructField(extraction_timestamp,TimestampType,true),StructField(op,StringType,true),StructField(start_datetime,TimestampType,true),StructField(end_datetime,TimestampType,true),StructField(is_current,BooleanType,false)))\n"
					]
				}
			],
			"source": [
				"full_load_updates.schema"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 6,
			"metadata": {
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [],
			"source": [
				"#full_load_updates.schema"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 20,
			"metadata": {
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"StructType(List(StructField(product_id,StringType,true),StructField(product_name,StringType,true),StructField(price,LongType,true),StructField(extraction_timestamp,TimestampType,true),StructField(op,StringType,false),StructField(start_datetime,TimestampType,true),StructField(end_datetime,TimestampType,true),StructField(is_current,BooleanType,false)))\n"
					]
				}
			],
			"source": [
				"full_load.schema"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 21,
			"metadata": {
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"+----------+------------+-----+--------------------+---+-------------------+-------------------+----------+\n",
						"|product_id|product_name|price|extraction_timestamp| op|     start_datetime|       end_datetime|is_current|\n",
						"+----------+------------+-----+--------------------+---+-------------------+-------------------+----------+\n",
						"|     00001|      Heater| 1000| 2023-01-01 01:01:01|  U|2023-01-01 01:01:01|2050-01-01 00:00:00|      true|\n",
						"|     00002|  Thermostat| 1000| 2023-01-01 01:01:01|  U|2023-01-01 01:01:01|2050-01-01 00:00:00|      true|\n",
						"|     00003|  Television| 1000| 2023-01-01 01:01:01|  U|2023-01-01 01:01:01|2050-01-01 00:00:00|      true|\n",
						"|     00004|     Blender| 1000| 2023-01-01 01:01:01|  U|2023-01-01 01:01:01|2050-01-01 00:00:00|      true|\n",
						"|     00005| USB charger| 1000| 2023-01-01 01:01:01|  U|2023-01-01 01:01:01|2050-01-01 00:00:00|      true|\n",
						"+----------+------------+-----+--------------------+---+-------------------+-------------------+----------+\n"
					]
				}
			],
			"source": [
				"full_load_updates.show()"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 22,
			"metadata": {
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"\n"
					]
				}
			],
			"source": [
				"\n",
				"full_load_updates.createOrReplaceTempView(f\"tmp_{table_name}_updates\")"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [],
			"source": [
				"\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 23,
			"metadata": {
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"DataFrame[]\n"
					]
				}
			],
			"source": [
				"query = f\"\"\"\n",
				"MERGE INTO {catalog_name}.{database_name}.{table_name} AS f\n",
				"USING (SELECT * FROM tmp_{table_name}_updates) AS u\n",
				"ON f.product_id = u.product_id\n",
				"WHEN MATCHED THEN UPDATE SET f.end_datetime = u.extraction_timestamp, f.is_current = False \n",
				"\n",
				"\"\"\"\n",
				"spark.sql(query)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 24,
			"metadata": {
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"+----------+------------+-----+--------------------+----+-------------------+-------------------+----------+\n",
						"|product_id|product_name|price|extraction_timestamp|  op|     start_datetime|       end_datetime|is_current|\n",
						"+----------+------------+-----+--------------------+----+-------------------+-------------------+----------+\n",
						"|     00004|     Blender|  100| 2022-01-01 01:01:01|None|2022-01-01 01:01:01|2023-01-01 01:01:01|     false|\n",
						"|     00001|      Heater|  250| 2022-01-01 01:01:01|None|2022-01-01 01:01:01|2023-01-01 01:01:01|     false|\n",
						"|     00003|  Television|  600| 2022-01-01 01:01:01|None|2022-01-01 01:01:01|2023-01-01 01:01:01|     false|\n",
						"|     00002|  Thermostat|  400| 2022-01-01 01:01:01|None|2022-01-01 01:01:01|2023-01-01 01:01:01|     false|\n",
						"|     00005| USB charger|   50| 2022-01-01 01:01:01|None|2022-01-01 01:01:01|2023-01-01 01:01:01|     false|\n",
						"+----------+------------+-----+--------------------+----+-------------------+-------------------+----------+\n"
					]
				}
			],
			"source": [
				"spark.table(f\"{catalog_name}.{database_name}.{table_name}\") \\\n",
				"    .show()"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [],
			"source": [
				"# query = f\"\"\"\n",
				"# SELECT tmp_{table_name}_updates.product_id as mergekey,tmp_{table_name}_updates.*\n",
				"# from tmp_{table_name}_updates\n",
				"\n",
				"# UNION ALL\n",
				"\n",
				"# SELECT * FROM {catalog_name}.{database_name}.{table_name}\n",
				"# ON {catalog_name}.{database_name}.{table_name}.product_id = tmp_{table_name}_updates.product_id\n",
				"# WHEN MATCHED THEN UPDATE SET f.end_datetime = u.extraction_timestamp, f.is_current = False\n",
				"\n",
				"# \"\"\"\n",
				"# spark.sql(query)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 113,
			"metadata": {
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"DataFrame[product_id: string, product_name: string, price: bigint, extraction_timestamp: timestamp, op: string, start_datetime: timestamp, end_datetime: timestamp, is_current: boolean]\n"
					]
				}
			],
			"source": [
				"# query = f\"\"\"\n",
				"# SELECT * FROM tmp_{table_name}_updates\n",
				"\n",
				"\n",
				"# UNION ALL\n",
				"\n",
				"# SELECT * FROM {catalog_name}.{database_name}.{table_name}\n",
				"\n",
				"\n",
				"# \"\"\"\n",
				"# spark.sql(query)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 114,
			"metadata": {
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"+----------+------------+-----+--------------------+---+-------------------+-------------------+----------+\n",
						"|product_id|product_name|price|extraction_timestamp| op|     start_datetime|       end_datetime|is_current|\n",
						"+----------+------------+-----+--------------------+---+-------------------+-------------------+----------+\n",
						"|     00004|     Blender|  100| 2022-01-01 01:01:01|  U|2022-01-01 01:01:01|2023-01-01 00:00:00|     false|\n",
						"|     00001|      Heater|  250| 2022-01-01 01:01:01|  U|2022-01-01 01:01:01|2023-01-01 00:00:00|     false|\n",
						"|     00003|  Television|  600| 2022-01-01 01:01:01|  U|2022-01-01 01:01:01|2023-01-01 00:00:00|     false|\n",
						"|     00002|  Thermostat|  400| 2022-01-01 01:01:01|  U|2022-01-01 01:01:01|2023-01-01 00:00:00|     false|\n",
						"|     00005| USB charger|   50| 2022-01-01 01:01:01|  U|2022-01-01 01:01:01|2023-01-01 00:00:00|     false|\n",
						"+----------+------------+-----+--------------------+---+-------------------+-------------------+----------+\n"
					]
				}
			],
			"source": [
				"# spark.table(f\"{catalog_name}.{database_name}.{table_name}\") \\\n",
				"#     .show()"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 38,
			"metadata": {
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"+----------+------------+-----+--------------------+----+-------------------+-------------------+----------+\n",
						"|product_id|product_name|price|extraction_timestamp|  op|     start_datetime|       end_datetime|is_current|\n",
						"+----------+------------+-----+--------------------+----+-------------------+-------------------+----------+\n",
						"|     00001|      Heater| 1000| 2023-01-01 00:00:00|null|2023-01-01 00:00:00|2050-01-01 00:00:00|     false|\n",
						"|     00002|  Thermostat| 1000| 2023-01-01 00:00:00|null|2023-01-01 00:00:00|2050-01-01 00:00:00|     false|\n",
						"|     00003|  Television| 1000| 2023-01-01 00:00:00|null|2023-01-01 00:00:00|2050-01-01 00:00:00|     false|\n",
						"|     00004|     Blender| 1000| 2023-01-01 00:00:00|null|2023-01-01 00:00:00|2050-01-01 00:00:00|     false|\n",
						"|     00005| USB charger| 1000| 2023-01-01 00:00:00|null|2023-01-01 00:00:00|2050-01-01 00:00:00|     false|\n",
						"|     00004|     Blender|  100| 2022-01-01 01:01:01|null|2022-01-01 01:01:01|2023-01-01 00:00:00|     false|\n",
						"|     00001|      Heater|  250| 2022-01-01 01:01:01|null|2022-01-01 01:01:01|2023-01-01 00:00:00|     false|\n",
						"|     00003|  Television|  600| 2022-01-01 01:01:01|null|2022-01-01 01:01:01|2023-01-01 00:00:00|     false|\n",
						"|     00002|  Thermostat|  400| 2022-01-01 01:01:01|null|2022-01-01 01:01:01|2023-01-01 00:00:00|     false|\n",
						"|     00005| USB charger|   50| 2022-01-01 01:01:01|null|2022-01-01 01:01:01|2023-01-01 00:00:00|     false|\n",
						"+----------+------------+-----+--------------------+----+-------------------+-------------------+----------+\n"
					]
				}
			],
			"source": [
				"# spark.table(f\"{catalog_name}.{database_name}.{table_name}\") \\\n",
				"#     .show()"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [],
			"source": []
		},
		{
			"cell_type": "code",
			"execution_count": 25,
			"metadata": {
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"\n"
					]
				}
			],
			"source": [
				"full_load_updates.writeTo(f\"{catalog_name}.{database_name}.{table_name}\").append()"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 26,
			"metadata": {
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"+----------+------------+-----+--------------------+----+-------------------+-------------------+----------+\n",
						"|product_id|product_name|price|extraction_timestamp|  op|     start_datetime|       end_datetime|is_current|\n",
						"+----------+------------+-----+--------------------+----+-------------------+-------------------+----------+\n",
						"|     00001|      Heater| 1000| 2023-01-01 01:01:01|   U|2023-01-01 01:01:01|2050-01-01 00:00:00|      true|\n",
						"|     00002|  Thermostat| 1000| 2023-01-01 01:01:01|   U|2023-01-01 01:01:01|2050-01-01 00:00:00|      true|\n",
						"|     00003|  Television| 1000| 2023-01-01 01:01:01|   U|2023-01-01 01:01:01|2050-01-01 00:00:00|      true|\n",
						"|     00004|     Blender| 1000| 2023-01-01 01:01:01|   U|2023-01-01 01:01:01|2050-01-01 00:00:00|      true|\n",
						"|     00005| USB charger| 1000| 2023-01-01 01:01:01|   U|2023-01-01 01:01:01|2050-01-01 00:00:00|      true|\n",
						"|     00004|     Blender|  100| 2022-01-01 01:01:01|None|2022-01-01 01:01:01|2023-01-01 01:01:01|     false|\n",
						"|     00001|      Heater|  250| 2022-01-01 01:01:01|None|2022-01-01 01:01:01|2023-01-01 01:01:01|     false|\n",
						"|     00003|  Television|  600| 2022-01-01 01:01:01|None|2022-01-01 01:01:01|2023-01-01 01:01:01|     false|\n",
						"|     00002|  Thermostat|  400| 2022-01-01 01:01:01|None|2022-01-01 01:01:01|2023-01-01 01:01:01|     false|\n",
						"|     00005| USB charger|   50| 2022-01-01 01:01:01|None|2022-01-01 01:01:01|2023-01-01 01:01:01|     false|\n",
						"+----------+------------+-----+--------------------+----+-------------------+-------------------+----------+\n"
					]
				}
			],
			"source": [
				"spark.table(f\"{catalog_name}.{database_name}.{table_name}\") \\\n",
				"    .show()"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 13,
			"metadata": {
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"\n"
					]
				}
			],
			"source": [
				"#updates.writeTo(f\"{catalog_name}.{database_name}.{table_name}\").createOrReplace()"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 10,
			"metadata": {
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"\n"
					]
				}
			],
			"source": [
				"import pyspark.sql.functions as f"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 4,
			"metadata": {
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"3.4332275390625e-05\n"
					]
				}
			],
			"source": [
				"import time\n",
				"start = time.time()\n",
				"print(time.time()-start)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 8,
			"metadata": {
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"1684516751.7\n"
					]
				}
			],
			"source": [
				"round(start,1)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 11,
			"metadata": {
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"45.95531153678894\n"
					]
				}
			],
			"source": [
				"start = time.time()\n",
				"full_load = spark.read.option('header','true').parquet(\"s3://sb-test-bucket-ireland/dummy_data/full_load.parquet\")\n",
				"full_load = full_load.withColumn(\"start_datetime\",f.col(\"extraction_timestamp\"))\n",
				"full_load = full_load.withColumn(\"end_datetime\", f.to_timestamp(f.lit(\"2050-01-01\"), 'yyyy-MM-dd'))\n",
				"full_load = full_load.withColumn(\"op\",f.lit(\"None\"))\n",
				"full_load = full_load.withColumn(\"is_current\",f.lit(True))\n",
				"full_load.sortWithinPartitions(\"product_name\") \\\n",
				"    .writeTo(f\"{catalog_name}.{database_name}.{table_name}\") \\\n",
				"    .create()\n",
				"spark.catalog.listTables(database_name)\n",
				"full_load_updates = spark.read.option('header','true').parquet(\"s3://sb-test-bucket-ireland/dummy_data/updates.parquet\")\n",
				"full_load_updates = full_load_updates.withColumn(\"start_datetime\",f.col(\"extraction_timestamp\"))\n",
				"full_load_updates = full_load_updates.withColumn(\"end_datetime\", f.to_timestamp(f.lit(\"2050-01-01\"), 'yyyy-MM-dd'))\n",
				"full_load_updates = full_load_updates.withColumn(\"is_current\",f.lit(True))\n",
				"\n",
				"full_load_updates.createOrReplaceTempView(f\"tmp_{table_name}_updates\")\n",
				"query = f\"\"\"\n",
				"MERGE INTO {catalog_name}.{database_name}.{table_name} AS f\n",
				"USING (SELECT * FROM tmp_{table_name}_updates) AS u\n",
				"ON f.product_id = u.product_id\n",
				"WHEN MATCHED THEN UPDATE SET f.end_datetime = u.extraction_timestamp, f.is_current = False \n",
				"\n",
				"\"\"\"\n",
				"spark.sql(query)\n",
				"full_load_updates.writeTo(f\"{catalog_name}.{database_name}.{table_name}\").append()\n",
				"print(time.time()-start)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [],
			"source": []
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [],
			"source": []
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [],
			"source": []
		},
		{
			"cell_type": "code",
			"execution_count": 29,
			"metadata": {
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"+----------+------------+-----+--------------------+----+-------------------+-------------------+----------+\n",
						"|product_id|product_name|price|extraction_timestamp|  op|     start_datetime|       end_datetime|is_current|\n",
						"+----------+------------+-----+--------------------+----+-------------------+-------------------+----------+\n",
						"|     00004|     Blender|  100| 2022-01-01 01:01:01|None|2022-01-01 01:01:01|2023-01-01 01:01:01|     false|\n",
						"|     00001|      Heater|  250| 2022-01-01 01:01:01|None|2022-01-01 01:01:01|2023-01-01 01:01:01|     false|\n",
						"|     00003|  Television|  600| 2022-01-01 01:01:01|None|2022-01-01 01:01:01|2023-01-01 01:01:01|     false|\n",
						"|     00002|  Thermostat|  400| 2022-01-01 01:01:01|None|2022-01-01 01:01:01|2023-01-01 01:01:01|     false|\n",
						"|     00005| USB charger|   50| 2022-01-01 01:01:01|None|2022-01-01 01:01:01|2023-01-01 01:01:01|     false|\n",
						"|     00001|      Heater| 1000| 2023-01-01 01:01:01|   U|2023-01-01 01:01:01|2050-01-01 00:00:00|      true|\n",
						"|     00002|  Thermostat| 1000| 2023-01-01 01:01:01|   U|2023-01-01 01:01:01|2050-01-01 00:00:00|      true|\n",
						"|     00003|  Television| 1000| 2023-01-01 01:01:01|   U|2023-01-01 01:01:01|2050-01-01 00:00:00|      true|\n",
						"|     00004|     Blender| 1000| 2023-01-01 01:01:01|   U|2023-01-01 01:01:01|2050-01-01 00:00:00|      true|\n",
						"|     00005| USB charger| 1000| 2023-01-01 01:01:01|   U|2023-01-01 01:01:01|2050-01-01 00:00:00|      true|\n",
						"+----------+------------+-----+--------------------+----+-------------------+-------------------+----------+\n"
					]
				}
			],
			"source": [
				"spark.table(f\"{catalog_name}.{database_name}.{table_name}\") \\\n",
				"    .show()"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [],
			"source": []
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [],
			"source": []
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"## Slowly Changing Dimension Type 2 - Complex\n",
				"This is a more complex SCD2 process which takes into account:\n",
				"Late arriving records where an update is processed with an extraction_timestamp that is later than the extraction_timestamp of the last processed record\n",
				"Batches which contain multiple updates to the same primary key\n",
				"The process can be summarised as follows:\n",
				"\n",
				"Concat/union updates with the existing data\n",
				"Sort by primary key and extraction_timestamp\n",
				"Window by primary key and set the end_datetime to the next record's extraction_timestamp, otherwise set it to a future distant timestamp\n",
				"The process could be optimised by separating records which have not received any updates, but this is left out to make the logic easier to follow."
			]
		},
		{
			"cell_type": "code",
			"execution_count": 14,
			"metadata": {
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"\n"
					]
				}
			],
			"source": [
				"late_updates = spark.read.option('header','true').parquet(\"s3://sb-test-bucket-ireland/data-engineering-use-cases/dummy-data/late_updates.parquet\")"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [],
			"source": []
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [],
			"source": []
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"Functions"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [],
			"source": [
				"from pyspark.sql import SparkSession, functions as F\n",
				"from pyspark.sql.types import StructType, StructField, IntegerType, Row\n",
				"import time\n",
				"\n",
				"\n",
				"def bulk_insert(input_filepath,output_directory,future_end_datetime):\n",
				"    start = time.time()\n",
				"    full_load=spark.read.option('header','true').parquet(input_filepath)\n",
				"    full_load = full_load.withColumn(\"start_datetime\",F.col(\"extraction_timestamp\"))\n",
				"    full_load = full_load.withColumn(\"end_datetime\", F.to_timestamp(F.lit(future_end_datetime), 'yyyy-MM-dd'))\n",
				"    full_load = full_load.withColumn(\"op\",F.lit(\"None\"))\n",
				"    full_load = full_load.withColumn(\"is_current\",F.lit(True))\n",
				"    full_load.sortWithinPartitions(\"product_name\") \\\n",
				"    .writeTo(output_directory) \\\n",
				"    .create()\n",
				"    print(time.time()-start)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 24,
			"metadata": {
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"\n"
					]
				}
			],
			"source": [
				"updates_filepath =\"s3://sb-test-bucket-ireland/data-engineering-use-cases/dummy-data/updates.parquet\"\n",
				"primary_key = \"product_id\""
			]
		},
		{
			"cell_type": "code",
			"execution_count": 27,
			"metadata": {
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"\n"
					]
				}
			],
			"source": [
				"def scd2_simple(input_filepath, updates_filepath, output_directory, future_end_datetime, primary_key):\n",
				"    start = time.time()\n",
				"    full_load_updates = spark.read.option('header','true').parquet(updates_filepath)\n",
				"    full_load_updates = full_load_updates.withColumn(\"start_datetime\",F.col(\"extraction_timestamp\"))\n",
				"    full_load_updates = full_load_updates.withColumn(\"end_datetime\", F.to_timestamp(F.lit(future_end_datetime), 'yyyy-MM-dd'))\n",
				"    full_load_updates = full_load_updates.withColumn(\"is_current\",F.lit(True))\n",
				"\n",
				"    full_load_updates.createOrReplaceTempView(f\"tmp_{table_name}_updates\")\n",
				"    query = f\"\"\"\n",
				"    MERGE INTO {catalog_name}.{database_name}.{table_name} AS f\n",
				"    USING (SELECT * FROM tmp_{table_name}_updates) AS u\n",
				"    ON f.product_id = u.product_id\n",
				"    WHEN MATCHED THEN UPDATE SET f.end_datetime = u.extraction_timestamp, f.is_current = False \n",
				"\n",
				"    \"\"\"\n",
				"    spark.sql(query)\n",
				"    full_load_updates.writeTo(f\"{catalog_name}.{database_name}.{table_name}\").append()\n",
				"    print(time.time()-start)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 28,
			"metadata": {
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"23.577928066253662\n"
					]
				}
			],
			"source": [
				"scd2_simple(input_filepath, updates_filepath, output_directory, future_end_datetime, primary_key)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [],
			"source": [
				"def scd2_complex(input_filepath, updates_filepath, output_directory, future_end_datetime, primary_key):\n",
				"    start = time.time()\n",
				"    print(time.time()-start)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [],
			"source": []
		}
	],
	"metadata": {
		"kernelspec": {
			"display_name": "Glue PySpark",
			"language": "python",
			"name": "glue_pyspark"
		},
		"language_info": {
			"codemirror_mode": {
				"name": "python",
				"version": 3
			},
			"file_extension": ".py",
			"mimetype": "text/x-python",
			"name": "Python_Glue_Session",
			"pygments_lexer": "python3"
		}
	},
	"nbformat": 4,
	"nbformat_minor": 4
}
